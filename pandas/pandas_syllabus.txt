PANDAS DATA MANIPULATION AND ANALYSIS - COMPREHENSIVE DETAILED SYLLABUS
==========================================================================

MODULE 1: PANDAS FUNDAMENTALS
------------------------------
1.1 Introduction to Pandas
    - What is pandas
        * Python data analysis library
        * Built on NumPy foundation
        * Key data structures: Series and DataFrame
        * Primary tool for data manipulation
        * Developed by Wes McKinney
    - Installation and setup
        * pip install pandas
        * conda install pandas
        * Import conventions: import pandas as pd
        * Version checking: pd.__version__
        * Dependencies (numpy, pytz, dateutil)
    - Data analysis workflow
        * Data loading and reading
        * Data cleaning and preparation
        * Data transformation and manipulation
        * Data analysis and computation
        * Data visualization integration
    - Pandas vs other tools
        * vs NumPy: Higher-level, labeled data
        * vs Excel: Programmatic, scalable
        * vs SQL: In-memory, Python integration
        * vs R: Python ecosystem integration

1.2 Core Data Structures
    - Series fundamentals
        * One-dimensional labeled array
        * Homogeneous data type
        * Index-value pairs
        * Based on NumPy array
    - Series creation
        * From lists: pd.Series([1, 2, 3])
        * From dictionaries: pd.Series({'a': 1, 'b': 2})
        * From scalar values: pd.Series(5, index=['a', 'b', 'c'])
        * From NumPy arrays: pd.Series(np.array([1, 2, 3]))
        * With custom index: pd.Series([1, 2, 3], index=['x', 'y', 'z'])
    - Series attributes
        * values: Underlying NumPy array
        * index: Index object
        * dtype: Data type
        * name: Series name
        * shape: Dimensions
        * size: Number of elements
        * ndim: Number of dimensions (always 1)
    - DataFrame fundamentals
        * Two-dimensional labeled data structure
        * Columns can have different data types
        * Like a table or spreadsheet
        * Collection of Series objects
    - DataFrame creation
        * From dictionaries: pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
        * From lists of lists: pd.DataFrame([[1, 2], [3, 4]])
        * From NumPy arrays: pd.DataFrame(np.array([[1, 2], [3, 4]]))
        * From Series: pd.DataFrame({'A': series1, 'B': series2})
        * With custom index/columns
    - DataFrame attributes
        * values: Underlying NumPy array
        * index: Row labels
        * columns: Column labels
        * dtypes: Data types of columns
        * shape: Dimensions (rows, columns)
        * size: Total number of elements
        * ndim: Number of dimensions (always 2)
        * info(): Comprehensive information
        * describe(): Statistical summary

1.3 Index Objects
    - Index fundamentals
        * Immutable sequence
        * Labels for Series/DataFrame
        * Enables label-based selection
        * Hierarchical indexing support
    - Index types
        * RangeIndex: Default integer index
        * Int64Index: Integer labels
        * Float64Index: Float labels
        * DatetimeIndex: Time-based index
        * TimedeltaIndex: Duration-based index
        * PeriodIndex: Period-based index
        * CategoricalIndex: Categorical labels
        * MultiIndex: Hierarchical index
    - Index creation
        * pd.Index([1, 2, 3]): Basic index
        * pd.RangeIndex(start, stop, step): Range index
        * pd.date_range(): Date range index
        * pd.period_range(): Period index
        * pd.timedelta_range(): Timedelta index
    - Index operations
        * Indexing and slicing
        * Set operations (union, intersection, difference)
        * Alignment in operations
        * Index arithmetic
        * Duplicate handling
    - Index methods
        * set_index(): Set column as index
        * reset_index(): Reset to default index
        * reindex(): Conform to new index
        * sort_index(): Sort by index
        * drop_duplicates(): Remove duplicates

MODULE 2: DATA LOADING AND SAVING
----------------------------------
2.1 Reading Data
    - CSV files
        * pd.read_csv(): Basic CSV reading
            - filepath_or_buffer parameter
            - Delimiter specification (sep, delimiter)
            - Header handling (header, names)
            - Index column specification (index_col)
            - Data type specification (dtype, converters)
            - Missing value handling (na_values, keep_default_na)
            - Parsing options (parse_dates, date_parser)
            - Chunk reading (chunksize, iterator)
            - Compression support (compression)
            - Encoding specification (encoding)
        * Advanced CSV options
            - Skip rows/columns (skiprows, usecols)
            - Comment handling (comment)
            - Quoting and escaping (quotechar, escapechar)
            - Whitespace handling (skipinitialspace)
            - Error handling (error_bad_lines, warn_bad_lines)
            - Memory optimization (low_memory, engine)
    - Excel files
        * pd.read_excel(): Excel file reading
            - Multiple sheet handling (sheet_name)
            - Engine specification (xlrd, openpyxl, xlsxwriter)
            - Cell range specification (usecols, skiprows)
            - Header and index handling
            - Data type conversion
        * Multiple sheets
            - Reading all sheets: sheet_name=None
            - Specific sheets: sheet_name=['Sheet1', 'Sheet2']
            - Sheet by index: sheet_name=0
    - JSON files
        * pd.read_json(): JSON reading
            - Orientation types (split, records, index, columns, values)
            - Date parsing (date_unit, convert_dates)
            - Compression support
            - Lines parameter for JSON lines
        * Nested JSON handling
            - json_normalize(): Flatten nested JSON
            - Record path specification
            - Metadata handling
    - SQL databases
        * pd.read_sql(): SQL query execution
            - Connection specification
            - Query or table name
            - Index column specification
            - Chunk reading support
            - Parameter binding
        * pd.read_sql_query(): Execute SQL query
        * pd.read_sql_table(): Read entire table
        * Database connections
            - SQLite: sqlite3 connection
            - PostgreSQL: psycopg2, SQLAlchemy
            - MySQL: pymysql, SQLAlchemy
            - SQL Server: pyodbc, SQLAlchemy
    - Other formats
        * HTML tables: pd.read_html()
            - Table parsing from web pages
            - Match specification
            - Header detection
            - Attribute filtering
        * HDF5: pd.read_hdf()
            - Hierarchical data format
            - Key specification
            - Query support
        * Parquet: pd.read_parquet()
            - Columnar storage format
            - Engine specification (pyarrow, fastparquet)
            - Column selection
        * Pickle: pd.read_pickle()
            - Python object serialization
            - Compressed pickle support
        * Feather: pd.read_feather()
            - Fast binary format
            - Cross-language support
        * ORC: pd.read_orc()
            - Optimized row columnar format
        * XML: pd.read_xml()
            - XML document parsing
            - XPath support
            - Namespace handling

2.2 Writing Data
    - CSV export
        * DataFrame.to_csv(): Write to CSV
            - Path specification
            - Separator customization (sep)
            - Index inclusion (index)
            - Header inclusion (header)
            - Column selection (columns)
            - Missing value representation (na_rep)
            - Float formatting (float_format)
            - Date formatting (date_format)
            - Encoding specification (encoding)
            - Compression options (compression)
            - Append mode support (mode)
        * Series.to_csv(): Series to CSV
    - Excel export
        * DataFrame.to_excel(): Write to Excel
            - File path specification
            - Sheet name customization
            - Engine selection (xlsxwriter, openpyxl)
            - Index and header control
            - Starting position (startrow, startcol)
        * Multiple sheets with ExcelWriter
            - Context manager usage
            - Sheet-by-sheet writing
            - Formatting options
    - JSON export
        * DataFrame.to_json(): Write to JSON
            - Orientation specification
            - Date formatting options
            - Compression support
            - Pretty printing (indent)
        * Series.to_json(): Series to JSON
    - SQL database export
        * DataFrame.to_sql(): Write to database
            - Table name specification
            - Connection object
            - If exists behavior (fail, replace, append)
            - Index inclusion
            - Data type specification (dtype)
            - Method specification (multi, callable)
        * Batch insertion optimization
        * Transaction handling
    - Other formats
        * HDF5: DataFrame.to_hdf()
            - Key specification
            - Compression options
            - Append mode
            - Table format vs fixed format
        * Parquet: DataFrame.to_parquet()
            - Engine selection
            - Compression algorithms
            - Index preservation
        * Pickle: DataFrame.to_pickle()
            - Protocol specification
            - Compression options
        * Feather: DataFrame.to_feather()
            - Index preservation
            - Compression support
        * XML: DataFrame.to_xml()
            - Root and row element names
            - Attribute vs element storage
            - Namespace support

2.3 Data Inspection
    - Basic information
        * head(n): First n rows
        * tail(n): Last n rows
        * info(): Data types and memory usage
        * describe(): Statistical summary
            - Include/exclude parameters
            - Percentiles specification
            - Datetime description
        * shape: Dimensions
        * columns: Column names
        * index: Index information
        * dtypes: Data types
        * memory_usage(): Memory consumption
    - Data exploration
        * sample(n): Random sampling
            - Sample size specification
            - Random state for reproducibility
            - Replacement option
            - Weights for weighted sampling
        * nunique(): Unique value counts
        * value_counts(): Frequency counts
            - Sort options (ascending, sort)
            - Normalization (normalize)
            - Bin specification for continuous data
            - Dropna handling
        * unique(): Unique values
        * duplicated(): Duplicate detection
            - Subset specification
            - Keep parameter (first, last, False)
        * isnull() / isna(): Missing value detection
        * notnull() / notna(): Non-missing detection
        * count(): Non-null count per column
    - Statistical methods
        * mean(): Arithmetic mean
        * median(): Middle value
        * mode(): Most frequent value
        * std(): Standard deviation
        * var(): Variance
        * min() / max(): Minimum/maximum values
        * quantile(): Quantile computation
        * corr(): Correlation matrix
            - Method specification (pearson, kendall, spearman)
            - Min periods parameter
        * cov(): Covariance matrix
        * skew(): Skewness measure
        * kurtosis(): Kurtosis measure

MODULE 3: DATA SELECTION AND INDEXING
--------------------------------------
3.1 Basic Selection
    - Column selection
        * Single column: df['column']
            - Returns Series
            - Dot notation: df.column
            - When dot notation fails
        * Multiple columns: df[['col1', 'col2']]
            - Returns DataFrame
            - Order specification
            - Column reordering
        * Column ranges: df.loc[:, 'start':'end']
            - Inclusive end
            - Label-based selection
    - Row selection
        * Integer indexing: df.iloc[0]
            - Single row as Series
            - Position-based selection
        * Multiple rows: df.iloc[[0, 1, 2]]
            - List of positions
            - Returns DataFrame
        * Row slicing: df.iloc[0:5]
            - Exclusive end
            - Step specification
        * Boolean indexing: df[condition]
            - Conditional row selection
            - Multiple conditions
    - Boolean indexing
        * Single condition: df[df['col'] > 5]
        * Multiple conditions
            - AND: df[(df['col1'] > 5) & (df['col2'] < 10)]
            - OR: df[(df['col1'] > 5) | (df['col2'] < 10)]
            - NOT: df[~(df['col'] > 5)]
        * String conditions
            - Contains: df[df['col'].str.contains('pattern')]
            - Starts/ends with: df[df['col'].str.startswith('prefix')]
            - String length: df[df['col'].str.len() > 5]
        * Isin() method: df[df['col'].isin(['value1', 'value2'])]
        * Between method: df[df['col'].between(5, 10)]
        * Query method: df.query('col1 > 5 and col2 < 10')
            - String expressions
            - Variable references with @
            - Method chaining friendly

3.2 Label-based Selection (loc)
    - Syntax and basics
        * df.loc[row_indexer, column_indexer]
        * Label-based selection
        * Inclusive end points
        * Single and multiple selection
    - Row selection with loc
        * Single row: df.loc['row_label']
        * Multiple rows: df.loc[['row1', 'row2']]
        * Row slicing: df.loc['start':'end']
        * Boolean indexing: df.loc[condition]
    - Column selection with loc
        * Single column: df.loc[:, 'column']
        * Multiple columns: df.loc[:, ['col1', 'col2']]
        * Column slicing: df.loc[:, 'start':'end']
        * All columns: df.loc[:, :]
    - Combined selection
        * Specific cells: df.loc['row', 'column']
        * Subsets: df.loc[['row1', 'row2'], ['col1', 'col2']]
        * Mixed selection: df.loc[condition, ['col1', 'col2']]
    - Advanced loc usage
        * Callable indexers: df.loc[lambda x: x['col'] > 5]
        * Assignment with loc: df.loc[condition, 'column'] = value
        * MultiIndex selection: df.loc[('level1', 'level2'), :]
    - Performance considerations
        * Single label vs list performance
        * Boolean mask efficiency
        * Chained indexing warnings

3.3 Position-based Selection (iloc)
    - Syntax and basics
        * df.iloc[row_indexer, column_indexer]
        * Integer position-based selection
        * Exclusive end points
        * Zero-based indexing
    - Row selection with iloc
        * Single row: df.iloc[0]
        * Multiple rows: df.iloc[[0, 1, 2]]
        * Row slicing: df.iloc[0:5]
        * Negative indexing: df.iloc[-1]
    - Column selection with iloc
        * Single column: df.iloc[:, 0]
        * Multiple columns: df.iloc[:, [0, 1, 2]]
        * Column slicing: df.iloc[:, 0:3]
        * All columns: df.iloc[:, :]
    - Combined selection
        * Specific cells: df.iloc[0, 1]
        * Subsets: df.iloc[0:3, 1:4]
        * Mixed ranges: df.iloc[[0, 2], 1:4]
    - Advanced iloc usage
        * Step specification: df.iloc[::2, ::2]
        * Random sampling: df.iloc[np.random.choice(len(df), size=10)]
        * Assignment with iloc: df.iloc[0, 1] = value
    - Comparison with loc
        * Position vs label
        * Performance differences
        * When to use each

3.4 Advanced Indexing
    - MultiIndex (Hierarchical Indexing)
        * Creating MultiIndex
            - pd.MultiIndex.from_arrays()
            - pd.MultiIndex.from_tuples()
            - pd.MultiIndex.from_product()
            - pd.MultiIndex.from_frame()
            - set_index() with multiple columns
        * MultiIndex attributes
            - levels: Index levels
            - codes: Integer codes
            - names: Level names
            - nlevels: Number of levels
        * MultiIndex selection
            - Single level: df.loc['level1_value']
            - Multiple levels: df.loc[('level1', 'level2')]
            - Partial selection: df.loc['level1']
            - Cross-section: df.xs('value', level='level_name')
        * MultiIndex slicing
            - Level-based slicing
            - IndexSlice for complex slicing
            - Slice tuples
    - Index alignment
        * Automatic alignment in operations
        * Missing data handling
        * Reindexing behavior
        * Join types in alignment
    - Index manipulation
        * set_index(): Column to index
            - Multiple columns
            - Append to existing
            - Drop original column
        * reset_index(): Index to column
            - Level specification
            - Drop index option
        * reindex(): Conform to new index
            - Fill methods
            - Interpolation options
        * sort_index(): Sort by index values
            - Level specification
            - Ascending/descending
            - Key function
    - Conditional selection methods
        * where(): Conditional replacement
            - Condition specification
            - Other value
            - Inplace option
        * mask(): Inverse of where
        * clip(): Limit values to range
            - Lower and upper bounds
            - Axis specification
        * filter(): Filter by label patterns
            - Items, like, regex parameters
            - Axis specification

MODULE 4: DATA CLEANING AND PREPARATION
----------------------------------------
4.1 Missing Data Handling
    - Detecting missing data
        * isnull() / isna(): Boolean mask
            - NaN, None, pd.NaT detection
            - DataFrame and Series usage
        * notnull() / notna(): Inverse detection
        * info(): Missing data summary
        * count(): Non-null counts
        * isna().sum(): Missing counts per column
        * isna().mean(): Missing percentages
    - Sources of missing data
        * NaN (Not a Number)
        * None values
        * pd.NaT (Not a Time)
        * Empty strings vs NaN
        * Custom missing indicators
    - Removing missing data
        * dropna(): Remove missing values
            - Axis specification (0 for rows, 1 for columns)
            - How parameter ('any', 'all')
            - Thresh parameter (minimum non-null values)
            - Subset parameter (specific columns)
            - Inplace option
        * dropna() strategies
            - Drop any missing: dropna()
            - Drop all missing: dropna(how='all')
            - Threshold-based: dropna(thresh=n)
            - Column-specific: dropna(subset=['col1', 'col2'])
    - Filling missing data
        * fillna(): Fill missing values
            - Value specification (scalar, dict, Series, DataFrame)
            - Method specification (ffill, bfill, interpolate)
            - Limit parameter (max consecutive fills)
            - Axis specification
            - Inplace option
        * Forward fill: fillna(method='ffill')
        * Backward fill: fillna(method='bfill')
        * Interpolation: interpolate()
            - Method specification (linear, polynomial, spline)
            - Axis specification
            - Limit parameter
            - Limit area specification
    - Advanced missing data techniques
        * Replace with statistics
            - Mean: fillna(df.mean())
            - Median: fillna(df.median())
            - Mode: fillna(df.mode().iloc[0])
        * Group-based filling
            - df.groupby('category')['column'].transform('mean')
            - Forward fill within groups
        * Custom filling functions
            - fillna(df.apply(custom_function))
            - Lambda functions for simple cases
        * Missing data visualization
            - Heatmaps of missing data
            - Missing data patterns

4.2 Duplicate Data Handling
    - Detecting duplicates
        * duplicated(): Boolean mask
            - Subset parameter (specific columns)
            - Keep parameter ('first', 'last', False)
        * Duplicate inspection
            - df[df.duplicated()]: View duplicates
            - df.duplicated().sum(): Count duplicates
            - value_counts() for frequency analysis
    - Removing duplicates
        * drop_duplicates(): Remove duplicate rows
            - Subset parameter (specific columns)
            - Keep parameter ('first', 'last', False)
            - Inplace option
            - Ignore_index option
        * Strategies for duplicate removal
            - Keep first occurrence: keep='first'
            - Keep last occurrence: keep='last'
            - Remove all duplicates: keep=False
            - Column-specific duplicates: subset=['col1', 'col2']
    - Handling complex duplicates
        * Partial duplicates (specific columns)
        * Case-sensitive vs case-insensitive
        * Whitespace handling
        * Custom duplicate logic
        * Aggregating duplicate information

4.3 Data Type Conversions
    - Basic type conversions
        * astype(): Explicit type conversion
            - Target type specification
            - Dictionary mapping for multiple columns
            - Error handling options
            - Copy parameter
        * Numeric conversions
            - to_numeric(): String to numeric
            - Error handling ('raise', 'coerce', 'ignore')
            - Downcast options ('integer', 'signed', 'unsigned', 'float')
        * String conversions
            - astype('str'): To string
            - str accessor for string methods
    - DateTime conversions
        * to_datetime(): Parse dates
            - Format specification
            - Error handling options
            - Inference options
            - UTC handling
            - Unit specification for timestamps
        * to_timedelta(): Parse time durations
            - Unit specification
            - Error handling
        * Date parsing strategies
            - Automatic inference
            - Custom format strings
            - Multiple format handling
    - Categorical data
        * Categorical type benefits
            - Memory efficiency
            - Ordered categories
            - Statistical operations
        * Creating categoricals
            - astype('category')
            - pd.Categorical() constructor
            - cut() and qcut() for binning
        * Category operations
            - Category addition/removal
            - Category reordering
            - Category renaming
    - Advanced type handling
        * Nullable integer types (Int64, Int32, etc.)
        * String type vs object type
        * Complex number handling
        * Custom data types
        * Type inference optimization
        * Memory usage optimization

4.4 String Data Cleaning
    - String accessor (.str)
        * Vectorized string operations
        * Method chaining capability
        * NaN handling in string operations
        * Performance with large datasets
    - Case operations
        * lower(): Convert to lowercase
        * upper(): Convert to uppercase
        * capitalize(): Capitalize first letter
        * title(): Title case conversion
        * swapcase(): Swap case
        * casefold(): Aggressive lowercase
    - Whitespace handling
        * strip(): Remove leading/trailing whitespace
        * lstrip(): Remove leading whitespace
        * rstrip(): Remove trailing whitespace
        * replace(): Replace patterns
            - Regex support with regex=True
            - Case sensitivity options
    - String pattern operations
        * contains(): Pattern matching
            - Regex support
            - Case sensitivity options
            - NaN handling
        * startswith() / endswith(): Position matching
            - Multiple pattern support
        * find(): Position finding
        * count(): Pattern counting
        * len(): String length
    - String splitting and joining
        * split(): Split strings
            - Delimiter specification
            - Max splits parameter
            - Expand option for DataFrame
        * rsplit(): Right-side splitting
        * join(): Join string lists
        * cat(): Concatenate strings
            - Separator specification
            - NaN handling
            - Other series concatenation
    - Advanced string operations
        * extract(): Extract groups with regex
            - Named groups
            - Multiple groups
            - Expand option
        * extractall(): Extract all matches
        * findall(): Find all matches
        * match(): Match at beginning
        * replace() with regex
            - Backreferences
            - Callable replacements
        * normalize(): Unicode normalization
        * encode() / decode(): Encoding operations
        * zfill(): Zero padding
        * pad(): General padding
            - Width specification
            - Fill character
            - Side specification

4.5 Data Validation and Quality
    - Data validation techniques
        * Range checking
            - Numeric ranges
            - Date ranges
            - String length limits
        * Format validation
            - Regex pattern matching
            - Email format validation
            - Phone number validation
        * Referential integrity
            - Foreign key validation
            - Lookup table checking
    - Data quality metrics
        * Completeness: Missing data ratios
        * Uniqueness: Duplicate detection
        * Consistency: Cross-field validation
        * Accuracy: Business rule checking
        * Timeliness: Recency checks
    - Outlier detection
        * Statistical methods
            - Z-score analysis
            - IQR method
            - Percentile-based detection
        * Visualization-based detection
            - Box plots
            - Scatter plots
            - Histogram analysis
        * Outlier handling strategies
            - Removal
            - Capping/flooring
            - Transformation
    - Data profiling
        * Summary statistics
        * Distribution analysis
        * Correlation analysis
        * Data relationship exploration
        * Automated profiling tools

MODULE 5: DATA TRANSFORMATION
------------------------------
5.1 Reshaping Data
    - Pivoting operations
        * pivot(): Reshape data
            - Index specification
            - Column specification
            - Values specification
            - Fill_value parameter
        * pivot_table(): Advanced pivoting
            - Aggregation functions
            - Multiple value columns
            - Margins (subtotals)
            - Fill_value handling
            - Dropna option
        * Pivot strategies
            - Wide to long format
            - Long to wide format
            - Multiple index levels
            - Handling duplicate entries
    - Melting operations
        * melt(): Unpivot data
            - ID variables (identifiers)
            - Value variables (to melt)
            - Variable name customization
            - Value name customization
            - Col_level for MultiIndex
        * wide_to_long(): Alternative melting
            - Stub name specification
            - Separator specification
            - Suffix specification
    - Stacking and unstacking
        * stack(): Pivot columns to rows
            - Level specification
            - Dropna option
        * unstack(): Pivot rows to columns
            - Level specification
            - Fill_value parameter
        * MultiIndex manipulation
            - Level swapping
            - Level reordering
            - Level dropping
    - Transposing
        * transpose() / T: Swap axes
            - Index becomes columns
            - Columns become index
            - Data type considerations
            - Memory implications
    - Advanced reshaping
        * crosstab(): Cross-tabulation
            - Row and column variables
            - Value specification
            - Aggregation functions
            - Normalization options
            - Margins inclusion
        * get_dummies(): One-hot encoding
            - Column specification
            - Prefix options
            - Separator customization
            - Dummy trap avoidance
            - Drop_first option

5.2 Merging and Joining
    - Merge operations
        * merge(): Join DataFrames
            - Join keys specification
            - Join type ('inner', 'outer', 'left', 'right')
            - Suffix handling for duplicate columns
            - Indicator option for merge tracking
        * Join types explained
            - Inner join: Intersection
            - Left join: All from left
            - Right join: All from right
            - Outer join: Union
        * Key specifications
            - Single key: on='key'
            - Multiple keys: on=['key1', 'key2']
            - Different key names: left_on='left_key', right_on='right_key'
            - Index-based joins: left_index=True, right_index=True
    - Concatenation
        * concat(): Combine DataFrames
            - Axis specification (0 for rows, 1 for columns)
            - Join type for column alignment
            - Ignore_index for continuous indexing
            - Keys for hierarchical indexing
            - Names for level naming
        * Concatenation strategies
            - Vertical stacking (axis=0)
            - Horizontal stacking (axis=1)
            - Mixed data type handling
            - Memory efficiency considerations
    - Join operations
        * join(): DataFrame method
            - Index-based joining
            - Join type specification
            - Suffix handling
            - Sort option
        * Comparison with merge()
            - Performance differences
            - Use case scenarios
            - Index alignment behavior
    - Advanced joining techniques
        * Multiple DataFrame merging
            - Chain merging
            - Reduce-based merging
            - functools.reduce with merge
        * Merge validation
            - one_to_one, one_to_many, many_to_one, many_to_many
            - Duplicate key detection
            - Data integrity checks
        * Performance optimization
            - Sort merge vs hash merge
            - Index optimization
            - Memory usage monitoring
    - Handling merge conflicts
        * Duplicate column names
            - Suffix strategies
            - Column renaming
        * Data type conflicts
            - Automatic type promotion
            - Manual type specification
        * Missing data in joins
            - Fill strategies
            - Indicator columns
            - Validation approaches

5.3 Grouping and Aggregation
    - GroupBy fundamentals
        * groupby(): Create grouped object
            - Single column grouping: df.groupby('column')
            - Multiple column grouping: df.groupby(['col1', 'col2'])
            - Custom grouping functions
            - Level-based grouping for MultiIndex
        * GroupBy object properties
            - groups: Dictionary of group labels to row indices
            - ngroups: Number of groups
            - size(): Size of each group
            - get_group(): Retrieve specific group
        * Iteration over groups
            - for name, group in df.groupby('column'):
            - Group name extraction
            - Group data manipulation
    - Aggregation methods
        * Basic aggregations
            - sum(): Sum values
            - mean(): Average values
            - count(): Count non-null values
            - size(): Count all values (including NaN)
            - std(): Standard deviation
            - var(): Variance
            - min() / max(): Minimum/maximum values
            - first() / last(): First/last values
        * Custom aggregations
            - agg(): Multiple functions
            - Custom function specification
            - Named aggregations
            - Different functions per column
        * Statistical aggregations
            - median(): Median value
            - quantile(): Quantile computation
            - nunique(): Unique value count
            - describe(): Comprehensive statistics
    - Transformation operations
        * transform(): Apply function keeping shape
            - Broadcasting results
            - Group-wise operations
            - Window functions
            - Normalization within groups
        * Common transformations
            - Group-wise standardization
            - Percentage of group total
            - Running calculations
            - Deviation from group mean
        * Lambda functions with transform
            - Simple transformations
            - Complex calculations
            - Multiple column operations
    - Filtering groups
        * filter(): Filter entire groups
            - Boolean function specification
            - Group-level conditions
            - Size-based filtering
        * Group filtering strategies
            - Statistical filters
            - Business rule filters
            - Data quality filters
    - Advanced GroupBy operations
        * apply(): Flexible group operations
            - Function specification
            - Arguments passing
            - Return type flexibility
            - Performance considerations
        * Multi-level grouping
            - Hierarchical aggregation
            - Level-specific operations
            - Index manipulation
        * Rolling and expanding operations
            - Time-based windows
            - Fixed-size windows
            - Expanding windows
        * Group-wise sorting
            - nlargest() / nsmallest()
            - Sort within groups
            - Top-N analysis

5.4 Time Series Manipulation
    - DateTime fundamentals
        * DateTime data types
            - Timestamp: Point in time
            - Timedelta: Duration
            - Period: Time span
        * Creating DateTime data
            - pd.to_datetime(): Parse dates
            - pd.date_range(): Generate date sequences
            - pd.period_range(): Generate period sequences
            - pd.timedelta_range(): Generate timedelta sequences
        * DateTime components
            - Year, month, day extraction
            - Hour, minute, second extraction
            - Weekday, day of year extraction
            - Quarter extraction
    - Time-based indexing
        * DatetimeIndex
            - Time-based row labels
            - Automatic chronological ordering
            - Partial string indexing
            - Date range selection
        * Partial string indexing
            - Year selection: df['2023']
            - Month selection: df['2023-03']
            - Date selection: df['2023-03-15']
            - Date range: df['2023-03-01':'2023-03-31']
        * Time-based slicing
            - Between dates
            - Before/after dates
            - Business day filtering
    - Resampling operations
        * resample(): Change frequency
            - Upsampling (higher frequency)
            - Downsampling (lower frequency)
            - Aggregation in downsampling
            - Interpolation in upsampling
        * Frequency aliases
            - D: Daily
            - W: Weekly  
            - M: Monthly
            - Q: Quarterly
            - A: Annual
            - H: Hourly
            - T/min: Minute
            - S: Second
        * Resampling methods
            - Forward fill (ffill)
            - Backward fill (bfill)
            - Linear interpolation
            - Aggregation functions
    - Time zone handling
        * Time zone aware vs naive
        * tz_localize(): Add timezone
        * tz_convert(): Convert timezone
        * UTC handling
        * Daylight saving time issues
    - Advanced time operations
        * Business day calculations
            - Business day ranges
            - Holiday handling
            - Custom business day rules
        * Time shifting
            - shift(): Move data points
            - Lead and lag operations
            - Percentage change calculation
        * Rolling windows
            - rolling(): Moving window calculations
            - Window size specification
            - Center alignment
            - Minimum periods
        * Seasonal analysis
            - Seasonal decomposition
            - Day of week patterns
            - Monthly patterns
            - Holiday effects

MODULE 6: DATA ANALYSIS AND STATISTICS
---------------------------------------
6.1 Descriptive Statistics
    - Summary statistics
        * describe(): Comprehensive summary
            - Include/exclude options
            - Percentile specification
            - Datetime-specific statistics
        * Central tendency
            - mean(): Arithmetic mean
            - median(): Middle value
            - mode(): Most frequent value
            - Geometric and harmonic means
        * Dispersion measures
            - std(): Standard deviation
            - var(): Variance
            - range calculation (max - min)
            - Interquartile range (IQR)
            - Mean absolute deviation
        * Shape measures
            - skew(): Skewness
            - kurtosis(): Kurtosis
            - Distribution shape analysis
    - Quantile operations
        * quantile(): Percentile calculation
            - Quantile specification
            - Interpolation methods
            - Axis specification
        * rank(): Ranking data
            - Method specification (average, min, max, first, dense)
            - Ascending/descending
            - Percentage ranks
        * Percentile-based analysis
            - Quartile calculation
            - Decile analysis
            - Custom percentile ranges
    - Frequency analysis
        * value_counts(): Frequency distribution
            - Sort options
            - Normalization
            - Bin specification for continuous data
            - Ascending/descending
        * nunique(): Unique value count
        * unique(): Unique values
        * Frequency tables
            - Single variable
            - Cross-tabulation
            - Proportion tables
    - Correlation and covariance
        * corr(): Correlation matrix
            - Method specification (pearson, kendall, spearman)
            - Minimum periods
            - Pairwise deletion
        * cov(): Covariance matrix
            - Denominator specification (N vs N-1)
            - Minimum periods
        * corrwith(): Correlation with Series/DataFrame
            - Cross-correlation
            - Axis specification
        * Correlation interpretation
            - Strength and direction
            - Statistical significance
            - Correlation vs causation

6.2 Hypothesis Testing
    - Statistical test preparation
        * Normality testing
            - Distribution visualization
            - Shapiro-Wilk test
            - Anderson-Darling test
            - Q-Q plots
        * Assumption checking
            - Independence
            - Equal variances
            - Sample size considerations
        * Test selection criteria
            - Parametric vs non-parametric
            - One-sample vs two-sample
            - Paired vs independent
    - Integration with scipy.stats
        * T-tests
            - One-sample t-test
            - Two-sample t-test
            - Paired t-test
        * Non-parametric tests
            - Mann-Whitney U test
            - Wilcoxon signed-rank test
            - Kruskal-Wallis test
        * Chi-square tests
            - Goodness of fit
            - Independence test
            - Homogeneity test
    - Effect size calculation
        * Cohen's d
        * Eta-squared
        * Correlation coefficient r
        * Practical significance
    - Multiple comparison correction
        * Bonferroni correction
        * False discovery rate
        * Family-wise error rate
        * P-value adjustment methods

6.3 Data Exploration Techniques
    - Exploratory data analysis (EDA)
        * Data overview
            - Dataset dimensions
            - Variable types
            - Missing data patterns
            - Basic statistics
        * Univariate analysis
            - Distribution analysis
            - Central tendency
            - Variability measures
            - Outlier detection
        * Bivariate analysis
            - Scatter plots
            - Correlation analysis
            - Cross-tabulations
            - Statistical relationships
        * Multivariate analysis
            - Correlation matrices
            - Principal component analysis
            - Cluster analysis
    - Pattern detection
        * Trend analysis
            - Time series trends
            - Seasonal patterns
            - Cyclical behavior
        * Anomaly detection
            - Statistical outliers
            - Business rule violations
            - Data quality issues
        * Relationship discovery
            - Linear relationships
            - Non-linear patterns
            - Interaction effects
    - Data profiling
        * Automated profiling
            - pandas-profiling library
            - Sweetviz library
            - Data quality reports
        * Custom profiling
            - Business-specific metrics
            - Domain knowledge integration
            - Interactive exploration

6.4 Advanced Analytics
    - Window functions
        * rolling(): Moving windows
            - Window size specification
            - Center alignment options
            - Minimum periods
            - Aggregation functions
        * expanding(): Cumulative windows
            - From start calculations
            - Minimum periods
        * ewm(): Exponential weighting
            - Alpha parameter
            - Half-life specification
            - Adjust parameter
    - Cumulative operations
        * cumsum(): Cumulative sum
        * cumprod(): Cumulative product
        * cummax() / cummin(): Cumulative extremes
        * cumcount(): Cumulative count
        * Running totals and percentages
    - Ranking and percentiles
        * Advanced ranking
            - Dense ranking
            - Competition ranking
            - Ordinal ranking
        * Percentile ranking
            - Within-group ranking
            - Cross-group ranking
        * Top-N analysis
            - nlargest() / nsmallest()
            - Group-wise top-N
    - Custom aggregations
        * User-defined functions
            - Complex calculations
            - Business logic implementation
            - Multi-step procedures
        * Vectorized operations
            - NumPy integration
            - Performance optimization
            - Broadcasting rules

MODULE 7: DATA VISUALIZATION INTEGRATION
-----------------------------------------
7.1 Basic Plotting
    - DataFrame plotting methods
        * plot(): General plotting interface
            - Kind specification (line, bar, hist, box, kde, area, pie, scatter, hexbin)
            - X and Y axis specification
            - Subplots creation
            - Figure size control
            - Color and style options
        * Line plots: df.plot() or df.plot.line()
            - Time series visualization
            - Multiple series
            - Marker styles
            - Line styles
        * Bar plots: df.plot.bar() / df.plot.barh()
            - Vertical and horizontal bars
            - Stacked bars
            - Grouped bars
            - Color customization
        * Histograms: df.plot.hist()
            - Bin specification
            - Density plots
            - Multiple columns
            - Alpha transparency
    - Series plotting
        * Series-specific plots
            - Line plots for time series
            - Bar plots for categorical data
            - Histograms for distributions
        * Series plot customization
            - Labels and titles
            - Axis formatting
            - Grid options
            - Legend control
    - Plot customization
        * Figure and axes control
            - Figure size: figsize parameter
            - Subplot arrangement
            - Axis labels and titles
            - Grid appearance
        * Style options
            - Color schemes
            - Line styles and markers
            - Transparency settings
            - Font properties
        * Legends and annotations
            - Legend positioning
            - Custom labels
            - Text annotations
            - Arrow annotations

7.2 Statistical Visualizations
    - Distribution plots
        * Histograms: df.hist()
            - Bin control
            - Density normalization
            - Overlay statistics
        * Density plots: df.plot.kde()
            - Kernel density estimation
            - Bandwidth selection
            - Multiple distributions
        * Box plots: df.plot.box()
            - Quartile visualization
            - Outlier identification
            - Group comparisons
        * Violin plots integration
            - Shape and distribution
            - Statistical summaries
            - Group comparisons
    - Correlation visualizations
        * Scatter plots: df.plot.scatter()
            - Relationship visualization
            - Size and color mapping
            - Trend lines
        * Scatter matrices: pd.plotting.scatter_matrix()
            - Multiple variable relationships
            - Diagonal histograms
            - Correlation overview
        * Correlation heatmaps
            - Color-coded correlations
            - Annotation options
            - Clustering dendrograms
    - Time series plots
        * Automatic datetime formatting
        * Multiple time series
        * Seasonal pattern visualization
        * Trend and seasonality decomposition
    - Categorical data visualization
        * Bar plots for counts
        * Stacked bars for proportions
        * Grouped bars for comparisons
        * Pie charts for composition

7.3 Integration with Matplotlib
    - Direct matplotlib integration
        * plt.figure() and df.plot()
        * Axes object manipulation
        * Subplot creation
        * Custom styling
    - Advanced matplotlib features
        * Multiple subplot layouts
        * Custom color maps
        * Advanced annotations
        * Animation capabilities
    - Figure management
        * Save figures to files
        * DPI and format control
        * Memory management
        * Batch plot generation

7.4 Integration with Seaborn
    - Seaborn data preparation
        * Long-form data requirements
        * Data melting for seaborn
        * Categorical variable handling
    - Statistical plotting
        * Regression plots
        * Distribution plots
        * Categorical plots
        * Matrix plots
    - Styling integration
        * Seaborn themes
        * Color palettes
        * Plot aesthetics
        * Style consistency

MODULE 8: PERFORMANCE OPTIMIZATION
-----------------------------------
8.1 Memory Management
    - Memory usage analysis
        * info(memory_usage='deep'): Detailed memory info
        * memory_usage(): Per-column memory
        * sys.getsizeof(): Object size
        * Memory profiling tools
    - Data type optimization
        * Categorical data for repeated strings
            - Memory reduction
            - Performance improvement
            - Statistical operations
        * Integer downcastinG
            - pd.to_numeric() with downcast
            - int8, int16, int32 selection
            - Nullable integer types
        * Float precision optimization
            - float32 vs float64
            - Precision requirements
            - Memory trade-offs
    - Sparse data structures
        * pd.SparseSeries and pd.SparseDataFrame (deprecated)
        * Sparse arrays in modern pandas
        * Memory efficiency for sparse data
        * Operations on sparse data
    - Memory-efficient loading
        * Chunking large files
            - chunksize parameter
            - Iterator processing
            - Incremental processing
        * Column selection during loading
            - usecols parameter
            - Reduce memory footprint
        * Data type specification
            - dtype parameter
            - Prevent automatic inference

8.2 Performance Optimization Techniques
    - Vectorization
        * NumPy operations over loops
        * Built-in pandas methods
        * avoid apply() when possible
        * Broadcasting rules
    - Efficient operations
        * Method chaining
            - Fluent interface
            - Intermediate variable reduction
            - Memory efficiency
        * In-place operations
            - inplace parameter
            - Memory conservation
            - Performance impact
        * Index optimization
            - Sorted indices for range selection
            - Unique indices for joins
            - Appropriate index types
    - Query optimization
        * query() method advantages
            - Readable syntax
            - Performance benefits
            - Reduced memory usage
        * Boolean indexing optimization
            - Simple conditions
            - Multiple condition combination
            - Short-circuit evaluation
        * eval() for complex expressions
            - NumExpr backend
            - Performance for large data
            - Expression complexity
    - Join optimization
        * Index-based joins
            - Sorted indices
            - Unique indices
            - Hash vs sort merge
        * Data type consistency
            - Matching types for keys
            - Avoid unnecessary conversions
        * Sort optimization
            - Pre-sorted data
            - Sort merge algorithms

8.3 Large Dataset Handling
    - Chunking strategies
        * File reading in chunks
        * Processing chunks separately  
        * Aggregating results
        * Memory management
    - Dask integration
        * Parallel processing
        * Larger-than-memory datasets
        * Familiar pandas API
        * Distributed computing
    - HDF5 for large data
        * Hierarchical storage
        * Compression options
        * Partial loading
        * Query capabilities
    - Parquet format
        * Column-oriented storage
        * Compression efficiency
        * Fast reading/writing
        * Schema evolution

8.4 Profiling and Debugging
    - Performance profiling
        * %timeit in Jupyter
        * Line profiling
        * Memory profiling
        * Bottleneck identification
    - Common performance pitfalls
        * Chained indexing
        * Unnecessary copies
        * Inefficient joins
        * Type conversions in loops
    - Debugging techniques
        * Data validation
        * Intermediate result inspection
        * Error message interpretation
        * Stack trace analysis
    - Best practices
        * Code organization
        * Function decomposition
        * Testing strategies
        * Documentation

MODULE 9: ADVANCED FEATURES
----------------------------
9.1 Custom Functions and Apply
    - apply() method variations
        * DataFrame.apply(): Row or column operations
            - Axis specification (0 for columns, 1 for rows)
            - Function arguments
            - Return type handling
            - Raw parameter for arrays
        * Series.apply(): Element-wise application
            - Custom transformations
            - Type conversions
            - Complex calculations
        * applymap(): Element-wise for DataFrames
            - Every cell transformation
            - Type-consistent operations
            - Performance considerations
    - Custom function development
        * Function design principles
            - Single responsibility
            - Clear inputs/outputs
            - Error handling
            - Documentation
        * Lambda functions
            - Simple transformations
            - Inline definitions
            - Limitations
        * Named functions
            - Reusability
            - Testing capability
            - Complex logic
        * Vectorized functions
            - NumPy integration
            - Performance optimization
            - Broadcasting support
    - Advanced apply techniques
        * Multiple column operations
            - Accessing multiple columns
            - Returning Series/DataFrames
            - Complex aggregations
        * Group-wise apply
            - Custom group operations
            - State preservation
            - Multiple output types
        * Conditional application
            - Boolean masking
            - Selective processing
            - Error handling
    - Performance considerations
        * apply() vs vectorized operations
        * Memory usage patterns
        * Alternative approaches
        * Profiling apply operations

9.2 MultiIndex Operations
    - MultiIndex creation strategies
        * From existing columns
            - set_index() with list
            - Multiple column selection
            - Level naming
        * From arrays/lists
            - pd.MultiIndex.from_arrays()
            - Separate arrays for each level
            - Level name specification
        * From tuples
            - pd.MultiIndex.from_tuples()
            - Tuple list input
            - Name specification
        * From product
            - pd.MultiIndex.from_product()
            - Cartesian product creation
            - Hierarchical structure
    - MultiIndex manipulation
        * Level operations
            - swaplevel(): Change level order
            - reorder_levels(): Rearrange levels
            - droplevel(): Remove levels
        * Index setting and resetting
            - set_index() variations
            - reset_index() with level specification
            - Partial reset
        * Sorting MultiIndex
            - sort_index() with level
            - Multiple level sorting
            - Ascending/descending per level
    - MultiIndex selection
        * Level-based selection
            - Single level: df.loc['level_value']
            - Multiple levels: df.loc[('level1', 'level2')]
            - Partial selection: df.loc['level1']
        * Cross-section selection
            - xs(): Extract cross-section
            - Level specification
            - Drop_level option
        * Advanced slicing
            - pd.IndexSlice for complex slicing
            - Slice objects
            - Boolean indexing with MultiIndex
    - MultiIndex aggregation
        * Level-specific grouping
            - groupby() with level parameter
            - Multiple level grouping
            - Custom aggregation functions
        * Hierarchical operations
            - sum() with level parameter
            - Statistical functions by level
            - Custom level functions
    - MultiIndex reshaping
        * stack() and unstack() with levels
            - Specific level stacking
            - Fill values for missing combinations
            - Level order control
        * pivot_table() with MultiIndex
            - Multiple index columns
            - Multiple aggregation functions
            - Hierarchical column structure

9.3 Window Functions
    - Rolling windows
        * Basic rolling operations
            - window size specification
            - Minimum periods requirement
            - Center alignment option
        * Rolling aggregations
            - Mean, sum, std, var
            - Min, max, median, quantile
            - Custom aggregation functions
            - Multiple statistics
        * Rolling with custom windows
            - Business day windows
            - Time-based windows
            - Irregular window sizes
    - Expanding windows
        * Cumulative calculations
            - From start calculations
            - Minimum periods handling
            - Growing window concept
        * Expanding statistics
            - Running means
            - Running standard deviations
            - Running correlations
            - Custom expanding functions
    - Exponentially weighted functions
        * EWM concept and applications
            - Exponential decay
            - Recent data emphasis
            - Smoothing applications
        * EWM parameters
            - Alpha (smoothing factor)
            - Half-life specification
            - Span parameter
            - Adjust parameter
        * EWM statistics
            - Mean (EWMA)
            - Standard deviation
            - Variance
            - Correlation
    - Advanced window operations
        * Custom window functions
            - Complex calculations
            - Multiple column operations
            - State-dependent functions
        * Window function optimization
            - Vectorized operations
            - Memory management
            - Performance considerations
        * Time-aware windows
            - Business day handling
            - Holiday adjustments
            - Custom calendars

9.4 Extension Data Types
    - Pandas extension arrays
        * Concept and benefits
            - Custom data types
            - Better missing data handling
            - Domain-specific optimizations
        * Built-in extensions
            - Categorical
            - Nullable integers (Int64, Int32, etc.)
            - String type
            - Boolean with NA
    - Categorical data advanced
        * Category management
            - Adding categories
            - Removing categories
            - Reordering categories
            - Category renaming
        * Ordered categoricals
            - Order specification
            - Comparison operations
            - Statistical benefits
        * Memory and performance
            - String deduplication
            - Integer encoding
            - Operation efficiency
    - Nullable data types
        * Nullable integers
            - Int8, Int16, Int32, Int64
            - NA vs NaN distinction
            - Boolean operations
        * Nullable boolean
            - Three-state logic (True, False, NA)
            - Logical operations
            - Comparison behavior
        * String data type
            - vs object dtype
            - Memory efficiency
            - String operations
    - Creating custom extensions
        * Extension array interface
            - Abstract methods
            - Data storage
            - Operation implementation
        * Type registration
            - Pandas type system
            - Method dispatch
            - Integration points
        * Performance considerations
            - Vectorized operations
            - Memory layout
            - Compatibility requirements
